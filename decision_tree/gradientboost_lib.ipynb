{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2f7458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score:\n",
      "  Precision Score = 0.021216\n",
      "  Recall Score = 0.804136\n",
      "  F1 Score = 0.041340\n",
      "  Accuracy Score = 0.582925\n",
      "  no_Leq = 55.975535\n",
      "  y_Leq = 55.937235\n",
      "  pred_Leq = 55.270739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import support \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def under_sampling(x):\n",
    "    import warnings\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    warnings.simplefilter('ignore', pd.core.common.SettingWithCopyWarning)\n",
    "    df = x\n",
    "    x_majority=df.loc[df.iloc[:,-1]==0]\n",
    "    x_minority=df.loc[df.iloc[:,-1]==1]\n",
    "    from sklearn.cluster import KMeans\n",
    "    km = KMeans(random_state=1, n_clusters=10)\n",
    "    km.fit(x_majority.iloc[:, :-1])\n",
    "    x_majority['Cluster'] = km.predict(x_majority.iloc[:, :-1])\n",
    "    ratio = x_majority['Cluster'].value_counts() / x_majority.shape[0]\n",
    "    n_sample_ary = (ratio * x_minority.shape[0]).sort_index().astype('int64')\n",
    "    df_Xs=[]\n",
    "    for i, n_sample in enumerate(n_sample_ary):\n",
    "        #重複を許すか許さないかで変わるのか？\n",
    "        df_Xs.append(x_majority[x_majority['Cluster']==i].sample(n=n_sample, replace=True))\n",
    "\n",
    "    df_Xs.append(x_minority)\n",
    "    x=pd.concat(df_Xs, sort=True)\n",
    "    x=x.drop('Cluster', axis=1)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def calc_avg(x, y):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    df_x=pd.DataFrame(x)\n",
    "    df_y=pd.DataFrame(y)\n",
    "    df_x_raw=df_x[(df_x.shape[1]-1)/2]\n",
    "    raw_df=pd.concat([df_x_raw, df_y], axis=1)\n",
    "    raw_df.columns=range(raw_df.shape[1])\n",
    "    df_ex=raw_df.loc[raw_df[1]==0]\n",
    "    N=len(df_ex)\n",
    "    Leq=10*np.log10(np.sum(np.power(10, df_ex[0]/10)))-10*np.log10(N)\n",
    "    return Leq\n",
    "\n",
    "def calc_avg2(x, y):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    df_x=pd.DataFrame(x)\n",
    "    df_y=pd.DataFrame(y)\n",
    "    df_x_raw=df_x[(df_x.shape[1]-1)/2]\n",
    "    raw_df=pd.concat([df_x_raw, df_y], axis=1)\n",
    "    raw_df.columns=range(raw_df.shape[1])\n",
    "    df_ex=raw_df\n",
    "    N=len(df_ex)\n",
    "    Leq=10*np.log10(np.sum(np.power(10, df_ex[0]/10)))-10*np.log10(N)\n",
    "    return Leq\n",
    "\n",
    "df = pd.read_csv( os.path.join('dataset', 'learning_data_431975.csv'), header=None  )\n",
    "x = df[ df.columns[ :-1 ] ]\n",
    "y=  df[ df.columns[ -1 ] ]\n",
    "kf = KFold( n_splits=3, random_state=1, shuffle=True )\n",
    "pr=[]\n",
    "re=[]\n",
    "f1 = []\n",
    "ac = []\n",
    "y_Leq=[]\n",
    "pred_Leq=[]\n",
    "no_Leq=[]\n",
    "n = []\n",
    "\n",
    "for train_index, test_index in kf.split( x ):\n",
    "    x_train, x_test = x.loc[train_index, :].values, x.loc[test_index, :].values\n",
    "    y_train, y_test = y.loc[train_index].values, y.loc[test_index].values\n",
    "\n",
    "    # 学習データだけダウンサンプリング\n",
    "    y_data=y_train[:, np.newaxis]\n",
    "    data=np.concatenate([x_train, y_data], 1)\n",
    "    train_df=pd.DataFrame(data)\n",
    "    train_us=under_sampling(train_df)\n",
    "    index = train_us.index.tolist()\n",
    "    x_train=x_train[index]\n",
    "    y_train=y_train[index]\n",
    "   \n",
    "    gbdt = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.01, max_depth=4,random_state=0)\n",
    "    gbdt.fit(x_train, y_train)\n",
    "    z = gbdt.predict(x_test)\n",
    "\n",
    "    pr.append( precision_score( y_test, z ) )\n",
    "    re.append( recall_score( y_test, z) )\n",
    "    f1.append( f1_score( y_test, z ) )\n",
    "    ac.append( accuracy_score( y_test, z ) )\n",
    "    n.append( len( x_test ) / len( x ) )\n",
    "\n",
    "    #等価騒音レベル計算\n",
    "    no_Leq.append(calc_avg2(x_test, y_test))\n",
    "    y_Leq.append(calc_avg(x_test, y_test))\n",
    "    pred_Leq.append(calc_avg(x_test, z))\n",
    "\n",
    "    \n",
    "print( 'CV Score:' )\n",
    "print( '  Precision Score = %f'%( np.average( pr, weights=n ) ) )\n",
    "print( '  Recall Score = %f'%( np.average( re, weights=n ) ) )\n",
    "print( '  F1 Score = %f'%( np.average( f1, weights=n ) ) )\n",
    "print( '  Accuracy Score = %f'%( np.average( ac, weights=n ) ) )\n",
    "print( '  no_Leq = %f'%( np.average( no_Leq, weights=n ) ) )\n",
    "print( '  y_Leq = %f'%( np.average( y_Leq, weights=n ) ) )\n",
    "print( '  pred_Leq = %f'%( np.average( pred_Leq, weights=n ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8e3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
